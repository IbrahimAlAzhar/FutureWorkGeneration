{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_acl_24 = pd.read_csv(\"Dataset/df_acl_24_final.csv\")\n",
        "df_acl_23 = pd.read_csv(\"Dataset/df_acl_23_final.csv\")\n",
        "# # df_acl_23_final.csv"
      ],
      "metadata": {
        "id": "3zETzk_kGZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Future Work' extraction"
      ],
      "metadata": {
        "id": "lGnKMzh_447Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to extract 'Future Work' and the next five sentences, with periods\n",
        "def extract_future_work(text):\n",
        "    # Split text into sentences\n",
        "    sentences = text.split('.')\n",
        "    # Iterate through sentences to find 'Future Work'\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        if 'Future' in sentence:\n",
        "            # Extract the sentence containing 'Future Work' and the next five sentences\n",
        "            # Re-add the periods to each sentence as they are joined\n",
        "            extracted_text = '.'.join(sentences[i:i+5]).strip()\n",
        "            if not extracted_text.endswith('.'):\n",
        "                extracted_text += '.'  # Ensure the extracted text ends with a period\n",
        "            return extracted_text\n",
        "    return \"\"  # Return an empty string if 'Future Work' is not found\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "df['Extracted Future Work'] = df['Concatenated Text'].apply(extract_future_work)\n"
      ],
      "metadata": {
        "id": "CZkZXdffFAMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove rest sentences if you find any word from 'keywords_to_check'\n",
        "\n",
        "# Assuming df_acl_24 is already defined and 'Extracted Future Work' has been populated\n",
        "keywords_to_check = [\n",
        "    'acknowledgements','acknowledgments','acknowledgment','ethics', 'ethical', 'conclusion',\n",
        "    'broader impact', 'discussion', 'limitations', 'appendix','acknowledgement'\n",
        "]\n",
        "\n",
        "# Function to remove sentences after encountering specific keywords\n",
        "def remove_sentences_after_keywords(text):\n",
        "    sentences = text.split('.')  # Split into sentences\n",
        "    filtered_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Check if any keyword is in the current sentence\n",
        "        if any(keyword.lower() in sentence.lower() for keyword in keywords_to_check):\n",
        "            break  # Stop adding sentences if keyword is found\n",
        "        filtered_sentences.append(sentence)\n",
        "    # Join the sentences back into a single string with periods\n",
        "    return '.'.join(filtered_sentences).strip() + '.'\n",
        "\n",
        "# Apply the function to the 'Extracted Future Work' column\n",
        "df['Extracted Future Work'] = df['Extracted Future Work'].apply(remove_sentences_after_keywords)\n"
      ],
      "metadata": {
        "id": "DkBKyHGmEGTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'Extracted Future Work' is empty\n",
        "df = df[df['Extracted Future Work'].notna() & (df['Extracted Future Work'] != \"\")]\n",
        "# Reset the index of the DataFrame, dropping the old index\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "9qnbXdsx6AKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'Extracted Future Work' is exactly '.'\n",
        "df = df[df['Extracted Future Work'] != '.']\n",
        "\n",
        "# Optionally, reset the index if you want a clean, consecutive index after removing rows\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "JDfoPUWudu7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove content within parentheses\n",
        "def remove_parentheses(text):\n",
        "    if isinstance(text, str):\n",
        "        # Replace content within parentheses, including the parentheses\n",
        "        return re.sub(r'\\(.*?\\)', '', text)\n",
        "    return text  # Return the original text if it's not a string\n",
        "\n",
        "# Apply the function to each element in the DataFrame\n",
        "df = df.applymap(remove_parentheses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1cI_uMRP0Fv",
        "outputId": "75291395-7915-4642-f608-c762f66bb39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-a241001aaf8e>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(remove_parentheses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXHmv-UEYPhI"
      },
      "outputs": [],
      "source": [
        "# convert to string\n",
        "df = df.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58UD51Y1Im7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b474d72e-8419-4337-f0e5-f5ff47ad0298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ca3585b80a12>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: str(x) if isinstance(x, float) else x)\n"
          ]
        }
      ],
      "source": [
        "# Convert Floats to Strings in All Columns:\n",
        "df = df.applymap(lambda x: str(x) if isinstance(x, float) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93ggPAYWIc0A"
      },
      "outputs": [],
      "source": [
        "# remove '\\n' charachter from 'all columns'\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    sentences = text.split('.')\n",
        "    cleaned_sentences = [sentence.replace('\\n', ' ').strip() for sentence in sentences]\n",
        "    return '. '.join(cleaned_sentences).strip()\n",
        "\n",
        "for column in df.columns:\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "measuring Average Cosine Similarity"
      ],
      "metadata": {
        "id": "e_dTfCbT4oB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aIAOfeoedcY",
        "outputId": "1809dc41-3e86-4915-c052-b79b933d8553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/255.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/255.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def calculate_average_cosine_similarity(df, base_col, other_col):\n",
        "    # Embed the text of the base column and the other column\n",
        "    base_embeddings = model.encode(df[base_col].fillna(\"\").tolist(), convert_to_tensor=True)\n",
        "    other_embeddings = model.encode(df[other_col].fillna(\"\").tolist(), convert_to_tensor=True)\n",
        "\n",
        "    # Ensure both tensors are on CPU before calculating cosine similarity\n",
        "    base_embeddings = base_embeddings.cpu()\n",
        "    other_embeddings = other_embeddings.cpu()\n",
        "\n",
        "    # Calculate cosine similarities and return the average\n",
        "    similarities = cosine_similarity(base_embeddings, other_embeddings)\n",
        "    return np.mean(similarities)\n",
        "\n",
        "# Columns to exclude from comparison (e.g., non-text columns or the 'limitation' itself)\n",
        "columns_to_exclude = ['Extracted Future Work']\n",
        "\n",
        "# Store the results\n",
        "average_similarities = {}\n",
        "\n",
        "# Iterate over all columns except the 'limitation' column\n",
        "for col in df.columns:\n",
        "    if col not in columns_to_exclude:\n",
        "        avg_sim = calculate_average_cosine_similarity(df, 'Extracted Future Work', col)\n",
        "        average_similarities[col] = avg_sim\n",
        "\n",
        "# Print average cosine similarities\n",
        "print(average_similarities)\n"
      ],
      "metadata": {
        "id": "of1IhZY14tpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame and 'Extracted Future Work' is the column of interest\n",
        "\n",
        "# Function to calculate the number of words in a string\n",
        "def word_count(text):\n",
        "    words = text.split()  # Split the text into words based on whitespace\n",
        "    return len(words)  # Return the number of words\n",
        "\n",
        "# Apply the function to the 'Extracted Future Work' column to get word counts for each row\n",
        "df['Word Count'] = df['Extracted Future Work'].apply(word_count)\n",
        "\n",
        "# Calculate the average word count across all rows\n",
        "average_word_count = df['Word Count'].mean()\n",
        "\n",
        "# Print the average word count\n",
        "print(f\"Average Word Count: {average_word_count:.2f}\")\n"
      ],
      "metadata": {
        "id": "v2aJLgVi4xHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'Word Count' is less than 10\n",
        "df = df[df['Word Count'] >= 10]\n",
        "\n",
        "# Optionally, reset the index if you want a clean, consecutive index after removing rows\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Z6M74C6MiEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('df_data_preprocessed.csv', index=False)"
      ],
      "metadata": {
        "id": "fyFeul5Hhx9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}