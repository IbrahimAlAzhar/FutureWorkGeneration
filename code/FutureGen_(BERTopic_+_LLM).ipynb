{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LLM Prompt"
      ],
      "metadata": {
        "id": "OBqBR3GrdxR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt describes information given to all conversations\n",
        "system_prompt = \"\"\"\n",
        "You are a helpful, respectful and honest assistant for labeling topics.\n",
        "\"\"\"\n",
        "\n",
        "main_prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "The topic is described by the following keywords: [KEYWORDS]\n",
        "\n",
        "Based on the information above, extract a short topic label in the following format:\n",
        "topic: <topic label>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = system_prompt  + main_prompt\n"
      ],
      "metadata": {
        "id": "d530kMpwdzwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTopic + LLM"
      ],
      "metadata": {
        "id": "iwjjBgerd6BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "import numpy as np\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import openai\n",
        "import tiktoken\n",
        "from bertopic.representation import OpenAI\n",
        "from bertopic import BERTopic\n",
        "import nltk\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "metadata": {
        "id": "7IxZlZZtd5xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from bertopic.representation import OpenAI\n",
        "from bertopic import BERTopic\n",
        "\n",
        "silhouette_score_list = []\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "# cluster_model = KMeans(31)\n",
        "embeddings = sentence_model.encode(df1['Future Work'], show_progress_bar=False)\n",
        "# Tokenizer\n",
        "tokenizer= tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "# others: gpt-4-turbo-preview\t, gpt-4, \tgpt-4-0613\t, gpt-4-32k\t, gpt-4-32k-0613\n",
        "\n",
        "# umap_model = UMAP(n_neighbors=13, n_components=15,min_dist=0.0, metric='cosine',random_state=42)\n",
        "\n",
        "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
        "\n",
        "# Create your representation model\n",
        "client = openai.OpenAI(api_key=\"\")\n",
        "\n",
        "representation_model = OpenAI(\n",
        "    client,\n",
        "    model=\"gpt-4o-mini\",\n",
        "    delay_in_seconds=2,\n",
        "    chat=True,\n",
        "    nr_docs=4,\n",
        "    doc_length=100,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt = prompt\n",
        ")\n",
        "\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=\"thenlper/gte-small\",\n",
        "    zeroshot_min_similarity=.75,\n",
        "    representation_model=representation_model,\n",
        "    vectorizer_model=vectorizer_model\n",
        ")\n",
        "\n",
        "topics, probs = topic_model.fit_transform(df1['Future Work'], embeddings)\n",
        "\n",
        "# Generate `X` and `labels` only for non-outlier topics (as they are technically not clusters)\n",
        "umap_embeddings = topic_model.umap_model.transform(embeddings)\n",
        "indices = [index for index, topic in enumerate(topics) if topic != -1]\n",
        "X = umap_embeddings[np.array(indices)]\n",
        "labels = [topic for index, topic in enumerate(topics) if topic != -1]\n",
        "\n",
        "  # Calculate silhouette score\n",
        "print(silhouette_score(X, labels))\n",
        "most_representative_words_llm = topic_model.get_topic_info()\n",
        "\n",
        "from keybert import KeyBERT\n",
        "\n",
        "kw_model = KeyBERT()\n",
        "doc_embeddings, word_embeddings = kw_model.extract_embeddings(df1[\"Future Work\"])\n",
        "keywords = kw_model.extract_keywords(df1[\"Future Work\"], doc_embeddings=doc_embeddings, word_embeddings=word_embeddings)\n",
        "print(keywords)\n",
        "most_representative_words_llm.to_csv(\"most_representative_words_llm1.csv\",index=False)"
      ],
      "metadata": {
        "id": "O-8RD5Mod_ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "measuring coherence score"
      ],
      "metadata": {
        "id": "Da93FGJxegXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_only = [[word for word, _ in sublist] for sublist in keywords]\n",
        "# convert list to string\n",
        "df1[\"Future Work\"] = df1[\"Future Work\"].apply(lambda x: ''.join(x))\n",
        "# Tokenize the strings to create a list of lists\n",
        "list_of_tokens = df1[\"Future Work\"].apply(lambda x: x.split()).tolist()\n",
        "\n",
        "word2id = Dictionary( list_of_tokens )\n",
        "\n",
        "# Coherence model\n",
        "cm = CoherenceModel(topics= words_only,\n",
        "                    texts=list_of_tokens,\n",
        "                    coherence='c_v',\n",
        "                    dictionary=word2id)\n",
        "\n",
        "coherence_per_topic = cm.get_coherence_per_topic()\n",
        "print(coherence_per_topic)\n",
        "\n",
        "import statistics\n",
        "print(statistics.mean(coherence_per_topic))"
      ],
      "metadata": {
        "id": "KC9KKK43ej9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualization"
      ],
      "metadata": {
        "id": "GcdgLXBnndJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_heatmap()"
      ],
      "metadata": {
        "id": "cr-GLeB-nd-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "\n",
        "# Run the visualization with the original embeddings\n",
        "topic_model.visualize_documents(df1['Future Work'], embeddings=embeddings)\n",
        "\n",
        "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
        "topic_model.visualize_documents(df1['Future Work'], reduced_embeddings=reduced_embeddings)"
      ],
      "metadata": {
        "id": "i0tyPXpCnflq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# topic_model = BERTopic()\n",
        "# topics, _ = topic_model.fit_transform(docs)\n",
        "topic_distr, _ = topic_model.approximate_distribution(df1['Future Work'], min_similarity=0)"
      ],
      "metadata": {
        "id": "KPqRnpFinfi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# don't use embedding_model = sentence model in 'BERTopic'\n",
        "topic_model = BERTopic(representation_model=representation_model,vectorizer_model=vectorizer_model,\n",
        "                          verbose=True, calculate_probabilities=True)\n",
        "\n",
        "topics, probs = topic_model.fit_transform(df1['Future Work'], embeddings)"
      ],
      "metadata": {
        "id": "aXG0o2-bnfey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To visualize the probabilities of topic assignment\n",
        "topic_model.visualize_distribution(probs[0])\n",
        "\n",
        "# To visualize the topic distributions in a document\n",
        "topic_model.visualize_distribution(topic_distr[0])\n"
      ],
      "metadata": {
        "id": "RpV7DuB5nfUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}