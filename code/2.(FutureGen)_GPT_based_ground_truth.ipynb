{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Dataset/df_data_preprocessed.csv\")"
      ],
      "metadata": {
        "id": "3zETzk_kGZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "generated_text = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    prompt = \"\"\"Your task is to refine the \"Future Work\" section of a scientific article by extracting only sentences\n",
        "    that are directly related to future research directions. Please focus on retaining content that discusses potential\n",
        "    areas for future investigation, further research needed, or additional strategies to improve the current study. \\n\"\"\" + df5['Extracted Future Work'][i]\n",
        "    summary_text = \"\"  # Initialize an empty string to collect the limitation text\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        # model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        stream=True,\n",
        "        temperature=0.2  # Adjust the temperature as needed, max_tokens=150\n",
        "    )\n",
        "\n",
        "    for chunk in stream:\n",
        "        summary_chunk = chunk.choices[0].delta.content or \"\"\n",
        "        summary_text += summary_chunk  # Append each chunk to the limitation_text\n",
        "\n",
        "    text_chunks = []\n",
        "    text_chunks.append(summary_text)\n",
        "    generated_text.append(summary_chunks)  # Append the collected limitation text to the list\n"
      ],
      "metadata": {
        "id": "nxfPtDRnPAqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt_ground_truth_future_work = pd.DataFrame(generated_text, columns=['GPT_ground_truth_FW'])\n",
        "df['GPT_ground_truth_FW'] = df_gpt_ground_truth_future_work['GPT_ground_truth_FW']"
      ],
      "metadata": {
        "id": "BlIGVypHOpa-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}